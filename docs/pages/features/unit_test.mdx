# Unit Test Generator

The Unit Test Generator feature is powered by kaizen and automatically creates comprehensive unit tests for your code, improving code quality and test coverage.

## How it Works:
- Input the source code or directory for which you want to generate unit tests.
- The Unit Test Generator leverages advanced language models to analyze the code and generate appropriate unit tests in a format compatible with popular testing frameworks.
- The generator supports multiple programming languages and can handle entire directories of code files.

You can find an example [here](https://github.com/Cloud-Code-AI/kaizen/tree/main/examples/unittest/main.py)

## Using the Unit Test Generator:
1. Provide the source code file or directory path for which you want to generate unit tests.
2. (Optional) Configure output path, verbosity, and critique settings.
3. Run the generator to create unit tests.
4. Review and integrate the generated tests into your test suite.

## Supported Languages:
- Python (.py)
- JavaScript (.js)
- TypeScript (.ts)
- React (.jsx, .tsx)
- Rust (.rs)

## How to Run:

### Installation

Before using the Unit Test Generator, you need to install the Kaizen Cloud Code SDK. You can do this using pip:

```bash
pip install kaizen-cloudcode
```

### Usage Guide

Here's a step-by-step guide on how to use the Unit Test Generator:

1. Import the UnitTestGenerator:
   ```python
   from kaizen.generator.unit_test import UnitTestGenerator
   ```

2. Create an instance of the generator:
   ```python
   generator = UnitTestGenerator()
   ```

3. Generate tests for a specific file:
   ```python
   generator.generate_tests(
       file_path="path/to/your/file.py",
       enable_critique=True,
       verbose=True
   )
   ```

4. (Optional) Run the generated tests:
   ```python
   test_results = generator.run_tests()
   ```

5. (Optional) Display the test results:
   ```python
   for file_path, result in test_results.items():
       print(f"Results for {file_path}:")
       if "error" in result:
           print(f"  Error: {result['error']}")
       else:
           print(f"  Tests run: {result.get('tests_run', 'N/A')}")
           print(f"  Failures: {result.get('failures', 'N/A')}")
           print(f"  Errors: {result.get('errors', 'N/A')}")
       print()
   ```

### Complete Example:

Here's a complete example of how to use the Unit Test Generator:

```python
from kaizen.generator.unit_test import UnitTestGenerator

# Create an instance of the generator
generator = UnitTestGenerator()

# Generate tests for a specific file
generator.generate_tests(
    file_path="kaizen/helpers/output.py",
    enable_critique=True,
    verbose=True
)

# Run the generated tests
test_results = generator.run_tests()

# Display the test results
for file_path, result in test_results.items():
    print(f"Results for {file_path}:")
    if "error" in result:
        print(f"  Error: {result['error']}")
    else:
        print(f"  Tests run: {result.get('tests_run', 'N/A')}")
        print(f"  Failures: {result.get('failures', 'N/A')}")
        print(f"  Errors: {result.get('errors', 'N/A')}")
    print()
```

## API Reference:

### Class: UnitTestGenerator

#### Constructor
- `__init__(self, verbose=False)`
  Initializes the UnitTestGenerator with optional verbosity setting.

#### Methods

##### generate_tests_from_dir
- `generate_tests_from_dir(self, dir_path: str, output_path: str = None)`
  Generates unit tests for all supported files in a given directory.
  - Parameters:
    - `dir_path`: Path of the directory containing source files.
     - `max_critique`: Maximum number of critique iterations.
    - `output_path`: (Optional) Custom output path for generated tests.
    - `verbose`: Enable verbose logging.
    - `enable_critique`: Enable AI critique and improvement of generated tests.
  - Returns: A tuple containing an empty dictionary and llm usage statistics.

##### generate_tests
- `generate_tests(self, file_path: str, content: str = None, max_critique: int = 3, output_path: str = None, verbose: bool = False, enable_critique: bool = False)`
  Generates unit tests for a given file with various configuration options.
  - Parameters:
    - `file_path`: Path of the file relative to the project root.
    - `content`: (Optional) File content.
    - `max_critique`: Maximum number of critique iterations.
    - `output_path`: (Optional) Custom output path for generated tests.
    - `verbose`: Enable verbose logging.
    - `enable_critique`: Enable AI critique and improvement of generated tests.
  - Returns: A tuple containing an empty dictionary and llm usage statistics.

##### run_tests
- `run_tests(self) -> Dict`
  Runs the generated unit tests and returns the results.

#### Key Features:
- Multi-language support
- Directory-wide test generation
- AI-powered test scenario creation
- Test critique and improvement
- Detailed logging and progress tracking
- Token usage monitoring

## Benefits:
- Increased Test Coverage
- Time Efficiency
- Consistency in Testing
- Early Bug Detection
- Support for Multiple Programming Languages
- Continuous Improvement through AI Critique

## Limitations:
- AI Limitations: May not cover all edge cases or complex scenarios.
- Human Oversight: Generated tests should be reviewed and potentially modified by developers.
- Language Support: Limited to the supported programming languages.

## Advanced Usage:
- Enable critique mode for AI-powered test improvement
- Adjust verbosity for detailed logging
- Customize output paths for generated tests
- Configure maximum critique iterations for fine-tuned results

The Unit Test Generator uses AI to enhance the testing process, improve code quality, and streamline the development workflow by automating the creation of unit tests across multiple programming languages.