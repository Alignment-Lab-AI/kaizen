## Unit Test Generator

Automatically create comprehensive unit tests for your code, improving code quality and test coverage.

### Key Features

1. **Unit Test Generation**: The feature analyzes the code changes and generates comprehensive unit tests, covering various scenarios and edge cases.

2. **Test Coverage**: The generated tests cover a wide range of scenarios, including edge cases, boundary conditions, and exception handling.

3. **Test Execution**: The tests can be executed locally or integrated into a CI/CD pipeline for automated testing.

4. **Test Reporting**: The feature provides detailed reports, including test results, coverage statistics, and any issues or failures encountered during execution.

5. **Continuous Integration**: The generated tests can be updated or regenerated as the codebase evolves, ensuring they remain aligned with the latest changes and requirements.

### How it Works

- Input the source code or directory for which you want to generate unit tests.
- The Unit Test Generator leverages advanced language models to analyze the code and generate appropriate unit tests in a format compatible with popular testing frameworks.
- The generator supports multiple programming languages and can handle entire directories of code files.

![Unit Test Generation Algo](/unit_test_generation_algo.png)

You can find an example [here](https://github.com/Cloud-Code-AI/kaizen/tree/main/examples/unittest/main.py)

## Usage Guide

Here's a detailed step-by-step guide on how to use the Unit Test Generator:

1. Follow the initial setup guide [here](../initial_setup_guide).

2. Create a new Python file and import the UnitTestGenerator module from Kaizen package :

   ```python
   from kaizen.generator.unit_test import UnitTestGenerator
   generator = UnitTestGenerator()
   ```

3. Provide the source code file or directory path for which you want to generate unit tests:  

   You can run it for one file at a time:

   ```python
   generator.generate_tests(
    file_path="path/to/your/file.py"
   )
   ```

   Or for a directory of files:

   ```python
   generator.generate_tests_from_dir(
    dir_path="path/to/your/directory"
   )
   ```

4. Optionally, you can configure output path, verbosity, and critique settings.

   ```python
   ...
    output_path="path/to/your/directory",
    enable_critique=True,
    verbose=True,
    max_critique=1
   ...
   ```

5. Run the generator to create unit tests.
   ```python
   generator.run_tests()
   ```
6. Display the test results:
   ```python
   for file_path, result in test_results.items():
       print(f"Results for {file_path}:")
       if "error" in result:
           print(f"  Error: {result['error']}")
       else:
           print(f"  Tests run: {result.get('tests_run', 'N/A')}")
           print(f"  Failures: {result.get('failures', 'N/A')}")
           print(f"  Errors: {result.get('errors', 'N/A')}")
       print()
   ```
7. Review and integrate the generated tests into your test suite.

### Example

Here's a complete example to generate unit tests for a specific file:

```python
from kaizen.generator.unit_test import UnitTestGenerator

# Create an instance of the generator
generator = UnitTestGenerator()

# Generate tests for a specific file
generator.generate_tests(
    file_path="kaizen/helpers/output.py",
    enable_critique=True,
    verbose=True
)

# Run the generated tests
test_results = generator.run_tests()

# Display the test results
for file_path, result in test_results.items():
    print(f"Results for {file_path}:")
    if "error" in result:
        print(f"  Error: {result['error']}")
    else:
        print(f"  Tests run: {result.get('tests_run', 'N/A')}")
        print(f"  Failures: {result.get('failures', 'N/A')}")
        print(f"  Errors: {result.get('errors', 'N/A')}")
    print()
```

### Supported Languages

- Python (.py)
- JavaScript (.js)
- TypeScript (.ts)
- React (.jsx, .tsx)
- Rust (.rs)

## Benefits

- Increased Test Coverage
- Time Efficiency
- Consistency in Testing
- Early Bug Detection
- Support for Multiple Programming Languages
- Continuous Improvement through AI Critique

## Limitations

- AI Limitations: May not cover all edge cases or complex scenarios.
- Human Oversight: Generated tests should be reviewed and potentially modified by developers.
- Language Support: Limited to the supported programming languages.